import streamlit as st
import json
import time
import os
from pathlib import Path
import tempfile

from config import (
    DEVICE, LANGUAGE, WHISPER_MODEL_SIZE,
    SIMILARITY_THRESHOLD, AI_CHARACTER_DEFAULT
)

from src.script_runner import ScriptRunner, parse_txt_script, parse_docx_script
from src.stt import SpeechRecognizer
from src.tts_synth import VoiceSynth
from src.audio_utils import record_to_wav

# ============================
# UI CONFIG
# ============================
st.set_page_config(page_title="IA partenaire th√©√¢tre", page_icon="üé≠", layout="centered")
st.title("üé≠ IA partenaire de r√©p√©tition ‚Äî V2 (fluide + multi-personnages)")

# ============================
# UPLOAD SCRIPT
# ============================
script_file = st.file_uploader("üìú Importer votre script (.json, .txt ou .docx)", type=["json", "txt", "docx"])

if not script_file:
    st.info("D√©pose un script pour commencer (format: JSON, TXT ou DOCX).")
    st.stop()

# Parse en fonction du type
if script_file.name.endswith(".json"):
    data = json.load(script_file)
elif script_file.name.endswith(".txt"):
    data = parse_txt_script(script_file, ai_character=AI_CHARACTER_DEFAULT)
else:
    data = parse_docx_script(script_file)

runner = ScriptRunner(data=data)

st.success(f"‚úÖ Script charg√© : **{runner.title}**")
st.caption(f"Langue : {runner.language} ‚Ä¢ R√©pliques : {len(runner.lines)}")

# ============================
# CHOIX DU PERSONNAGE + MODE
# ============================
speakers = sorted(list(runner.speakers))
default_idx = 0 if AI_CHARACTER_DEFAULT.upper() not in speakers else speakers.index(AI_CHARACTER_DEFAULT.upper())
your_role = st.selectbox("üé≠ Quel personnage joues-tu ?", speakers, index=default_idx)
runner.set_user_character(your_role)

mode = st.radio("Mode :", ["Performance (score global √† la fin)", "R√©p√©tition (feedback √† chaque r√©plique)"], horizontal=True)

# ============================
# TTS BACKEND + PARAMS
# ============================
backend = st.selectbox("Synth√®se vocale IA (TTS)", ["gtts"])  # on garde simple (gtts); tu peux remettre hf-api si besoin
custom_voice_path = None
hf_token = None

# Init STT/TTS
stt = SpeechRecognizer(model_size=WHISPER_MODEL_SIZE, device=DEVICE, language=LANGUAGE)
tts = VoiceSynth(backend=backend, language="fr")

# ============================
# SESSION STATE
# ============================
if "idx" not in st.session_state:
    st.session_state.idx = 0
if "results" not in st.session_state:
    st.session_state.results = []
if "cache_dir" not in st.session_state:
    st.session_state.cache_dir = "cache_tts"
    os.makedirs(st.session_state.cache_dir, exist_ok=True)
if "cache_tts" not in st.session_state:
    st.session_state.cache_tts = {}  # {line_index: outfile_path}

# ============================
# PR√â-G√âN√âRATION TTS (FLUIDIT√â)
# ============================
def pregenerate_ai_audio():
    progress = st.progress(0, text="Pr√©paration des voix IA‚Ä¶")
    ai_indexes = [i for i, ln in enumerate(runner.lines) if ln.speaker != runner.user_character]
    total = len(ai_indexes)
    for k, i in enumerate(ai_indexes, start=1):
        line = runner.lines[i]
        # Fichier d√©terministe pour √©viter de r√©g√©n√©rer
        base = f"{i:04d}_{line.speaker}"
        outfile = os.path.join(st.session_state.cache_dir, base + (".mp3" if backend == "gtts" else ".wav"))
        if not os.path.exists(outfile):
            tts.speak(line.text, outfile=outfile, autoplay=False)
        st.session_state.cache_tts[i] = outfile
        progress.progress(k / total, text=f"Pr√©paration des voix IA‚Ä¶ ({k}/{total})")
    progress.empty()
    st.success("‚úÖ Voix IA pr√©g√©n√©r√©es. La sc√®ne sera fluide üëå")

st.button("‚ö° Pr√©charger toutes les r√©pliques IA", on_click=pregenerate_ai_audio)

# ============================
# LECTURE AUTOMATIQUE DE LA SC√àNE
# ============================
def play_one_ai_line(i):
    """Fait parler l'IA (lecture auto + attend la fin de la r√©plique)"""
    line = runner.lines[i]

    # utilise le cache si dispo
    outfile = st.session_state.cache_tts.get(i)
    if not outfile:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3", dir=st.session_state.cache_dir)
        outfile = tts.speak(line.text, outfile=tmp.name, autoplay=True)
        st.session_state.cache_tts[i] = outfile
    else:
        tts.speak(line.text, outfile=outfile, autoplay=True)

    # ‚è±Ô∏è on estime la dur√©e de la r√©plique (150 mots/min = 2,5 mots/s)
    words = len(line.text.split())
    estimated_duration = max(2, words / 2.5)  # dur√©e minimale 2s
    time.sleep(estimated_duration)
def run_scene_automatic():
    scores_buffer = []
    with st.spinner("üé¨ La sc√®ne se joue automatiquement‚Ä¶"):
        # On repart de l'index courant
        i = st.session_state.idx
        while i < len(runner.lines):
            line = runner.lines[i]
            st.subheader(f"{line.speaker}")
            st.write(line.text)

            if line.speaker != runner.user_character:
                # IA parle (auto, sans bouton)
                play_one_ai_line(i)
                time.sleep(0.5)  # petit temps pour laisser d√©marrer l'audio


            else:

                # Tour de l'acteur (avec ou sans d√©lai)

                if not st.session_state.direct_mode:

                    st.info("üé§ √Ä toi ! (d√©but dans 2s)")
                    time.sleep(2)
                with st.spinner("üéôÔ∏è Enregistrement (6s)‚Ä¶"):
                    wav = record_to_wav("temp/actor.wav", seconds=6)
                transcript = stt.transcribe(wav)
                st.caption(f"Vous avez dit : {transcript}")

                ok, score = runner.validate_actor_line(transcript, threshold=SIMILARITY_THRESHOLD)
                if mode.startswith("R√©p√©tition"):
                    st.write(f"Similarit√© : {score:.1f}% (seuil {SIMILARITY_THRESHOLD})")
                    if ok:
                        st.success("‚úÖ R√©plique valid√©e")
                    else:
                        st.error("‚ùå Trop diff√©rent")
                else:
                    scores_buffer.append(score)

            i += 1
            st.session_state.idx = i
            # petit buffer pour laisser Streamlit mettre √† jour l'UI
            time.sleep(0.3)

    # Fin de sc√®ne
    st.success("üèÅ Fin de la sc√®ne.")
    tts.cleanup()

    if mode.startswith("Performance") and scores_buffer:
        final_score = round(sum(scores_buffer) / len(scores_buffer), 1)
        st.subheader("üìä R√©sultat final")
        st.write(f"Score global : **{final_score}%**")

        if final_score >= SIMILARITY_THRESHOLD:
            st.success("‚úÖ Sc√®ne r√©ussie !")
        else:
            st.warning("‚ö†Ô∏è Sc√®ne √† retravailler un peu.")

    # ============================
    # üîÅ Bouton de retour au menu
    # ============================
    # ============================
    # üîÅ Bouton de retour au menu
    # ============================
    if "should_reset" not in st.session_state:
        st.session_state.should_reset = False

    def ask_reset():
        st.session_state.should_reset = True

    st.divider()
    st.button("‚Ü©Ô∏è Revenir au menu principal", on_click=ask_reset)

    # Si le drapeau est activ√©, on r√©initialise tout
    if st.session_state.should_reset:
        for key in ["idx", "results", "cache_tts", "should_reset"]:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()

    st.divider()

# Option pour encha√Æner directement sans d√©lai entre IA et acteur
direct_mode = st.checkbox("‚è© Encha√Ænement direct (sans d√©lai entre les r√©pliques)", value=False)
st.session_state.direct_mode = direct_mode

st.button("üé≠ Lancer la sc√®ne (automatique)", on_click=run_scene_automatic)
